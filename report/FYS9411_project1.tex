\documentclass[a4paper,8pt]{article}
\usepackage[lmargin=20mm,rmargin=20mm,tmargin=20mm,bmargin=20mm]{geometry}
\usepackage{multicol}
\usepackage{amsmath,amssymb}
\usepackage{physics}
\DeclareMathOperator{\variance}{var}


\title{\small FYS9411 – Computational Physics II \\
\huge Variational Monte Carlo on a Bosonic Quantum Trap}
\author{\large Jonas Boym Flaten \\
\small University of Oslo}
\date{\today}

\begin{document}

\begin{multicols}{2}
[
\maketitle
\begin{abstract}
Using the Julia language, the Variational Monte Carlo method was implemented for an elliptical harmonic quantum trap system with and without particle interaction, and 2 variational parameters were tuned using the gradient descent algorithm. A comparison between two different Monte Carlo sampling methods, as well as statistical refinement of the results, is presented. |||noe mer om statistisk analyse||| Importance sampling using Langevin "quantum drift" sampling is shown to be superior to brute-force "random step" sampling. Finally, the effect of particle interaction is examined and discussed. |||noe mer om resultatene||| 
\end{abstract}
]

\section{Introduction}

As far as current human knowledge goes, Quantum Mechanics seems to be an excellent model of the universe at the smallest scales. In this "picoscopic" regime our world consists of fuzzy elementary particles, spreading diffusely through space but exchanging sharp energy quanta through the four fundamental mechanisms. One big caveat however is the rate at which a thorough quantum mechanical analysis becomes impossible to conduct. For anything more than 1 particle, the complexity of the system of differential equations to consider quickly becomes overwhelming. Add several interaction mechanisms at once and you are sure to end up with a problem that nobody on Earth has been able to solve analytically (yet).

The difficulties with analytical analysis of quantum many-particle systems encourages consideration of statistical and numerical methods. With the 
currently available computational power in one's own office and the advent of collaborative development of code over the internet, the field of Computational Physics has emerged as a third alternative to the traditional theoretical and experimental branches of research on physics. Especially within Quantum Mechanics, where the theoreticists face the complexity of coupled differential systems as discussed above while the experimentalists deal with the frailty (and cost) of experiments tuned to the extreme parameters of the quantum world, computational research is well-suited to the task. Through numerical simulations founded on statistical methods and analysis, large quantum mechanical systems can be explored with excellent precision.

In this text, the computational method of Variational Monte Carlo on an elliptical harmonic quantum trap system is considered, and its implementation in Julia and subsequent results are reported. The sections \ref{model} and \ref{theory} provide the concrete model in consideration and the principles leading up to the method. In section \ref{method} the actual implementation as well as the scientific approach to the problem is described. Finally in section \ref{results} the results are presented, discussed and compared to similar work.

|||noen referanser og aktualisering av det fysiske systemet kanskje?|||


\section{Model} \label{model}

\subsection{Quantum system} \label{system}
The quantum system in consideration is a $D$-dimensional quantum trap with an arbitrary number of identical particles $N$. In the position basis, the Hamiltonian is
\begin{equation}
H[\vec{R}] = \sum\limits_i^N \left(U[\vec{r}_i] -\frac{\hbar^2}{2m}\nabla_i^2 \right) + \sum\limits_i^N\sum\limits_{j > i}^N V[\vec{r}_i,\vec{r}_j]
\end{equation}
with
\begin{align}
U[\vec{r}_i] &= \frac{m\omega^2}{2}\left(x_i^2+y_i^2+\lambda^2z_i^2\right), \\
V[\vec{r}_i,\vec{r}_j] &= V[\Delta{r}_{ij}] =\begin{cases} \infty & \text{for $\Delta{r}_{ij} \leq a$} \\
0 & \text{for $\Delta{r}_{ij} > a$} \end{cases}.
\end{align}
In other words $U$ is an elliptical harmonic oscillator potential, and $V$ describes a hard-sphere interaction between the particles. In the equations above as well as the rest of this text, $\vec{r}_i$ and $\vec{\nabla}_i$ are the position and spatial derivative of each particle (indexed by $i$). Furthermore $\Delta\vec{r}_{ij} = \vec{r}_i-\vec{r}_j$ is the distance vector between the particles $i$ and $j$. Finally $\vec{R}$ is the configuration vector of the system as a whole (containing all the particle positions $\vec{r}_i$).

The parameters of the model are the mass of the particles $m$, the characteristic radius of the particles $a$ and the trap strength $\omega$, as well as the elliptic parameter $\lambda$ (which potentially makes the trap elliptical in the z-direction). However the variables of the system can be made dimensionless by introducing $\sqrt{\frac{\hbar}{m\omega}}$ as length unit and $\hbar\omega$ as energy unit by splitting
\begin{align}
&\vec{r}_i = \sqrt{\frac{\hbar}{m\omega}}\vec{r'}_i, \quad &\vec{\nabla}_i = \sqrt{\frac{m\omega}{\hbar}}\vec{\nabla'}_i, \nonumber\\
&H = \hbar\omega H', \quad\quad &a = \sqrt{\frac{\hbar}{m\omega}}a'. \nonumber
\end{align}
The primed variables $\vec{r'}_i$, $\vec{\nabla'}_i$, $H'$ and $a'$, are now dimensionless and give the relative size to the corresponding unit. The primed Hamiltonian takes the form
\begin{equation}
H[\vec{R'}] = \sum\limits_i^N \frac{1}{2}\left( U'[\vec{r'}_i] - {\nabla'}_i^2\right) + \sum\limits_i^N\sum\limits_{j > i}^N V'[\Delta{r'}_{ij}] \label{Hamiltonian}
\end{equation}
with
\begin{align}
U'[\vec{r'}_i] &= x_i^2+y_i^2+\lambda^2z_i^2, \label{U}\\
V'[\Delta{r'}_{ij}] &=\begin{cases} \infty & \text{for $\Delta{r'}_{ij} \leq a'$} \\
0 & \text{for $\Delta{r'}_{ij} > a'$} \end{cases}. \label{V}
\end{align}

In the rest of this text, we omit the primes and consider these dimensionless variables and equations.

\subsection{Trial state} \label{trialstate}

The trap particles are assumed to be bosons, and the variational trial state in consideration has the form in position basis
\begin{equation}
\Psi[\vec{R}] = \prod\limits_i^N g[\vec{r}_i] \prod\limits_j^N\prod\limits_{k > j}^N f[\vec{r}_j,\vec{r}_k] \label{trialstate}
\end{equation}
with
\begin{align}
g[\vec{r}_i] &= \epsilon^{-\alpha\left(x_i^2+y_i^2+ \beta z_i^2\right)}, \\
f[\vec{r}_i,\vec{r}_j] &= f[\Delta{r}_{ij}] = \begin{cases} 0 & \text{for $\Delta{r}_{ij} \leq a$} \\
1-\frac{a}{\Delta{r}_{ij}} & \text{for $\Delta{r}_{ij} > a$} \end{cases}.
\end{align}
Here $\alpha$ and $\beta$ are the variational parameters to tune when chasing the ground state energy.


\section{Theory} \label{theory}

\subsection{The variational method}
The variational principle of Quantum Mechanics states that the ground state $E_G$ of any quantum system with Hamiltonian operator $\mathbf{H}$ is bounded from above by
\begin{equation}
E_G \leq \frac{\ev{\mathbf{H}}{\Psi}}{\braket{\Psi}{\Psi}}
\end{equation}
for any state $\ket{\Psi}$, and the variational method is based on finding a suitable trial state which minimizes the bound $\frac{\ev{\mathbf{H}}{\Psi}}{\braket{\Psi}{\Psi}}$.

For $N$ particles in $D$ dimensions the bound takes the form
\begin{align}
\frac{\ev{\mathbf{H}}{\Psi}}{\braket{\Psi}{\Psi}} = \frac{\idotsint \Psi^*[\vec{R}]H[\vec{R}]\Psi[\vec{R}]\delta^{DN}R}{\idotsint \abs{\Psi[\vec{R}]}^2\delta^{3N}R} \nonumber
\end{align}
in position basis. Introducing now a quantity known as the local energy $\varepsilon$ as
\begin{equation}
\varepsilon[\vec{R}] = \frac{H[\vec{R}]\Psi[\vec{R}]}{\Psi[\vec{R}]}, \label{defLocalenergy}
\end{equation}
the bound can be rewritten to
\begin{equation}
\frac{\ev{\mathbf{H}}{\Psi}}{\braket{\Psi}{\Psi}} = \idotsint \Pi[\vec{R}]\varepsilon[\vec{R}] \delta^{DN}R, \nonumber
\end{equation}
where
\begin{equation}
\Pi[\vec{R}] = \frac{\abs{\Psi[\vec{R}]}^2}{\idotsint \abs{\Psi[\vec{R}]}^2\delta^{DN}R} \label{distribution}
\end{equation}
is a probability distribution over the configuration space spanned by $\vec{R}$. But then the variational principle can be recast as
\begin{equation}
E_G \leq \ev{\varepsilon}_\Pi,
\end{equation}
and so the variational method becomes a matter of estimating the expected local energy $\ev{\varepsilon}_\Pi$. At this probabilistic reinterpretation of the variational method, a Monte Carlo method enters the picture.

Monte Carlo methods in general are based on drawing a series of random samples from some relevant probability distribution and using statistics to harvest the desired results about the system in consideration. In the case of Variational Monte Carlo, the samples to draw are the local energies $\varepsilon$ and the relevant distribution is the trial state distribution $\Pi$ defined above. In appendix \ref{localenergy} the derivatives of the trial wavefunction $\Psi$ as defined in \eqref{trialstate} are calculated to find an analytical expression for the local energy $\varepsilon$ using its definition \eqref{defLocalenergy}. But even though the sample function $\varepsilon$ is known and the trial wavefunction $\Psi$ itself is defined, its corresponding distribution $\Pi$ involves a $DN$-dimensional integral which quickly becomes impossible to calculate both analytically and numerically.


\subsection{The Metropolis algorithm}
The Metropolis algorithm is an algorithm which makes it possible to sample from a just some probability distribution with an unknown constant, and hence is perfectly suited for Variational Monte Carlo. The algorithm is based on constructing an ergodic Markov chain with $\Pi$ as its stationary distribution and letting this Markov chain run from some initial configuration, sampling the local energy $\varepsilon$ along the way. The longer the Markov chain is allowed to run, the more of the distribution $\Pi$ is fleshed out, and the better the resulting mean value of $\varepsilon$ matches the actual expected value of $\varepsilon$. For $C$ Monte Carlo cycles, where one cycle is one step in the Markov chain, the mean value of $\varepsilon$, denoted from here on as $E_\text{VMC}$, is given by
\begin{equation}
E_\text{VMC} = \ev{\varepsilon} = \frac{1}{C}\sum\limits_{c = 1}^C \varepsilon[\vec{R}_c]
\end{equation}
and the statistical error of this compared to the true expected value $\ev{\varepsilon}_\Pi$ can be shown to be
\begin{equation} 
\Delta E_\text{VMC} = \sqrt{\frac{1}{C} \variance\varepsilon} = \sqrt{\frac{1}{C}\left(\frac{1}{C}\sum\limits_{c = 1}^C \varepsilon^2[\vec{R}_c] - \ev{\varepsilon}^2\right)}.
\end{equation}
In these equations, $c$ is an index of each cycle and $\vec{R}_c$ is the configuration at that cycle.

The Metropolis Markov chain is constructed from two transition probabilities: the proposal distribution $P[\vec{R}'|\vec{R}]$, which gives the probability of proposing a move to some configuration $\vec{R}'$ when the last sample was drawn at $\vec{R}$, and the acceptance probability $A[\vec{R}'|\vec{R}]$ which gives the probability of accepting this same proposed move. Note that while both $P$ and $A$ must take values between $0$ and $1$, $P$ must be a proper probability distribution in the sense that for all $\vec{R}$,
\begin{equation}
\sum\limits_j P[\vec{R}'|\vec{R}] = 1,
\end{equation}
while $A$ is only some probability function. The Markov matrix then has the transition rates
\begin{align}
&M[\vec{R}'|\vec{R}] = \nonumber\\
&A[\vec{R}'|\vec{R}]P[\vec{R}'|\vec{R}] + \delta_{ji}\sum\limits_{\vec{R}''} (1-A[\vec{R}''|\vec{R}])P[\vec{R}''|\vec{R}],
\end{align}
and by letting this matrix act on the target distribution $\Pi[\vec{R}]$ and requiring it to stay the same, the so-called "balance criterion" 
\begin{align}
&\sum\limits_{\vec{R}'} A[\vec{R}'|\vec{R}]P[\vec{R}'|\vec{R}]\Pi[\vec{R}] \nonumber\\
&\qquad = \sum\limits_{\vec{R}'} A[\vec{R}|\vec{R}']P[\vec{R}|\vec{R}']\Pi[\vec{R}']  \label{balance}
\end{align}
follows. If the Markov chain is further required to be ergodic, so that it is ensured to sample from all possible configurations given enough time, then the balance criterion turns into the "detailed balance criterion", in which the sums in \eqref{balance} are removed. Rewriting the detailed balance criterion, the following constraint is put on the acceptance rate $A$:
\begin{equation}
\frac{A[\vec{R}'|\vec{R}]}{A[\vec{R}|\vec{R}']} = \frac{P[\vec{R}|\vec{R}']\Pi[\vec{R}']}{P[\vec{R}'|\vec{R}]\Pi[\vec{R}]}.
\end{equation}
The simplest choice of $A$ to enforce this constraint is the "Metropolis choice", which is an acceptance probability given by
\begin{equation}
A[\vec{R}'|\vec{R}] = \min\left\{1,\frac{P[\vec{R}|\vec{R}']\Pi[\vec{R}']}{P[\vec{R}'|\vec{R}]\Pi[\vec{R}]}\right\}. \label{acc}
\end{equation}
With this definition of the acceptance probability, the Markov chain is ensured to sample from the target distribution $\Pi$, so that given enough Monte Carlo cycles the mean value of $\varepsilon$ will converge to its true expected value $\ev{\varepsilon}_\Pi$. While almost magical in its simplicity, it is now clear how the Metropolis algorithm can sample from $\Pi$ without ever calculating the large integral in \eqref{distribution}; because only a ratio of $\Pi$ values appears in the acceptance ratio above, the integral cancels out and is in some sense removed from the problem.

As for the proposal distribution $P$, it can in principle be any distribution, but the choice will affect both the acceptance ratio to be computed from \eqref{acc} as well as the number of Monte Carlo cycles required for the VMC energy $E_\text{VMC}$ to converge. Because the proposal distribution directly affects the moves which are proposed and thus sampled, the choice of proposal distribution corresponds to choosing a sampling method for the Metropolis algorithm. Note that because the trial wavefunction defined in \eqref{trialstate} is a product of functions which depend on only one or two particles each, the acceptance ratio computation simplifies significantly if only one random particle is chosen and moved in each move. In other words, by picking one random particle $i$ with probability $\frac{1}{N}$ and then drawing a move for this particle from some proposal distribution $P[\vec{R}'_i|\vec{R}]$, the acceptance probability reduces to
\begin{equation}
A[\vec{R}'_i|\vec{R}] = \min\left\{1,\frac{P[\vec{R}|\vec{R}'_i]}{P[\vec{R}'_i|\vec{R}]}\prod\limits_{j \neq i} \frac{g^2[\vec{r'}_i]f^2[\Delta r'_{ij}]}{g^2[\vec{r}_i]f^2[\Delta r_{ij}]}\right\}, \label{acc_i}
\end{equation}
where the only difference between the configurations $\vec{R}$ and $\vec{R}'_i$ is that the position $\vec{r}_i$ of the randomly chosen particle $i$ has changed to $\vec{r'}_i$.  Hence instead of computing the whole trial wavefunction at each Monte Carlo cycle, only the factors involving particle $i$ need to be computed.

Two sampling methods based on single particle moves will be considered in this text. In the first brute-force "random step" method, a new position for particle $i$ is drawn as
\begin{equation}
\vec{r'}_i = \vec{r}_i+\widetilde{\delta\vec{r}}, \label{propRS}
\end{equation}
where $\widetilde{\delta\vec{r}}$ is a stochastic vector drawn uniformly from the interval $-\delta s \leftrightarrow \delta s$ in each spatial direction for some fixed step size $\delta s$. The proposal distribution $P$ in this case is symmetric,
\begin{equation}
p[\vec{R}'_i|\vec{R}] = p[\vec{R}|\vec{R}'_i], \nonumber
\end{equation}
so the acceptance probability in \eqref{acc_i} reduces to
\begin{equation}
A[\vec{R}'_i|\vec{R}] = \min\left\{1,\prod\limits_{j \neq i} \frac{g^2[\vec{r'}_i]f^2[\Delta r'_{ij}]}{g^2[\vec{r}_i]f^2[\Delta r_{ij}]}\right\}. \label{accRS}
\end{equation}

\subsection{The quantum drift sampling method}

The second sampling method to be considered, referred to as the "quantum drift" method, is based on the Langevin equation – a stochastic differential equation originally introduced to consider Brownian motion. Its original full form is
\begin{equation}
m\frac{\delta^2\vec{r}}{\delta t^2} = -\gamma\frac{\delta\vec{r}}{\delta t}+\vec{F}[\vec{r}]+\widetilde{\vec{B}}, \label{originalLangevin}
\end{equation}
which is nothing else than Newton's second law for a particle subject to a frictional force $-\gamma\frac{\delta\vec{r}}{\delta t}$, an external force field $\vec{F}$ as well as a stochastic force $\widetilde{\vec{B}}$ meant to invoke random fluctuations of the particle's trajectory. In the case of a very strong frictional force the acceleration can be neglected, and the equation reduces to the overdamped Langevin equation
\begin{equation}
\frac{\delta\vec{r}}{\delta t} = \frac{\vec{F}[\vec{r}]}{\gamma}+\frac{\widetilde{\vec{B}}}{\gamma}, \label{overdampedLangevin}
\end{equation}
Using now the length unit set in section \ref{system} and introducing a suitable time unit, this equation can be made dimensionless and recast to
\begin{equation}
\frac{\delta\vec{r}}{\delta t} = \frac{1}{2}\vec{Q}[\vec{r}]+\widetilde{\vec{W}}, \label{Langevin}
\end{equation}
where $\vec{Q}$ is a dimensionless drift term and $\widetilde{\vec{W}}$ is a dimensionless stochastic term. Discretising this with the Euler-Maruyama method (a modified Euler method for stochastic differential equations) a new algorithm emerges for proposing moves for the random particle $i$ through
\begin{equation}
\vec{r'}_i = \vec{r}_i+\frac{1}{2}\vec{Q}_i[\vec{R}]\delta t + \widetilde{\delta\vec{r}}
\end{equation}
for some fixed small (dimensionless) time step $\delta t$ and a stochastic vector $\widetilde{\delta\vec{r}}$ drawn from a normal distribution with mean zero and deviation $\sqrt{\delta t}$ in each spatial direction. For some consistency with random step sampling $\delta s$ can be introduced as
\begin{equation}
\delta s = \sqrt{\delta t}
\end{equation}
to recast the proposal algorithm as
\begin{equation}
\vec{r'}_i = \vec{r}_i+\frac{1}{2}\vec{Q}_i[\vec{R}]\delta s^2 + \widetilde{\delta\vec{r}}, \label{propLD}
\end{equation}
in which $\widetilde{\delta\vec{r}}$ now is a stochastic vector drawn from a normal distribution with mean zero and deviation $\delta s$ in each spatial direction.

The proposal distribution $P$ for the algorithm in \eqref{propLD} is not symmetric, but can be found by considering the corresponding Fokker-Planck equation, which is a partial differential equation describing the time evolution of the spatial configuration distribution $\Pi$ when the Langevin equation is invoked. The Fokker-Planck equation corresponding to the overdamped Langevin equation \eqref{Langevin} is also known as the Smoluchowski equation and is given by
\begin{equation}
\frac{\delta\Pi}{\delta t} = \frac{1}{2}\vec{\nabla}_i\cdot\left(\vec{\nabla}_i-\vec{Q}_i\right)\Pi. \label{Smoluchowski}
\end{equation}
The spatial configuration distribution $\Pi$ is sure to remain constant as long as the drift term $\vec{Q}_i$ takes the form
\begin{equation}
\vec{Q}_i[\vec{R}] = \frac{\vec{\nabla}_i\Pi[\vec{R}]}{\Pi[\vec{R}]},
\end{equation}
and the proposal distribution $P$ turns out to be nothing else than the Green function
\begin{equation}
G[\delta t, \vec{R}'_i|\vec{R}] = \sqrt{\frac{1}{2\pi \delta s^2}}^{DN} \epsilon^{-\frac{\left(\vec{r'}_i-\vec{r}_i-\frac{1}{2}\vec{Q}_i[\vec{R}]\delta s^2\right)^2}{2\delta s^2}} \label{Green}
\end{equation}
of the Smoluchowski equation. In terms of Variational Monte Carlo the drift term is known as the "quantum drift" and takes the form
\begin{equation}
\vec{Q}_i[\vec{R}] = \frac{2\vec{\nabla}_i\Psi[\vec{R}]}{\Psi[\vec{R}]}. \label{defQuantumdrift}
\end{equation}
In appendix \ref{quantumdrift} an analytical expression for the quantum drift is found using the derivatives of the trial wavefunction $\Psi$ which were already calculated in appendix \ref{localenergy}. Noting that
\begin{align}
&\left(\vec{r'}_i-\vec{r}_i-\frac{1}{2}\vec{Q}_i[\vec{R}]\delta s^2 \right)^2-\left(\vec{r}_i-\vec{r'}_i-\frac{1}{2}\vec{Q}_i[\vec{R}'_i]\delta s^2\right)^2 \nonumber\\
&= -\left(\vec{r'}_i-\vec{r}_i\right) \cdot \left(\vec{Q}_i[\vec{R}'_i]+\vec{Q}_i[\vec{R}]\right)\delta s^2-\frac{\vec{Q}_i^2[\vec{R}'_i]-\vec{Q}_i^2[\vec{R}]}{4}\delta s^4 \nonumber\\
&= -\left(\vec{r'}_i-\vec{r}_i+\frac{\vec{Q}_i[\vec{R}'_i]-\vec{Q}_i[\vec{R}]}{4}\delta s^2\right)\cdot\left(\vec{Q}_i[\vec{R}'_i]+\vec{Q}_i[\vec{R}]\right)\delta s^2 \nonumber
\end{align}
the acceptance probability in \eqref{acc_i} reduces in this case to
\begin{align}
&A[\vec{R}'_i|\vec{R}] = \min\Bigg\{1, \nonumber\\
&\prod\limits_{j \neq i} \frac{g^2[\vec{r'}_i]f^2[\Delta r'_{ij}]}{g^2[\vec{r}_i]f^2[\Delta r_{ij}]}\epsilon^{-\frac{\vec{Q}_i[\vec{R}'_i]+\vec{Q}_i[\vec{R}]}{2}\cdot\left(\vec{r'}_i-\vec{r}_i+\frac{\vec{Q}_i[\vec{R}'_i]-\vec{Q}_i[\vec{R}]}{4}\delta s^2\right)}\Bigg\} \label{accLD}
\end{align}
when inserting the Green function in \eqref{Green} as the proposal distribution $P$.

The quantum drift moves the particles with the distribution gradient, towards configurations of higher probability, and thus ensures that the "most important" configurations are sampled early on. This is why the quantum drift sampling method is also known as importance sampling.

\subsection{The block resampling method}
|||beskrivelse av blocking|||

\subsection{The gradient descent algorithm}
|||beskrivelse av gradient descent|||

\section{Method} \label{method}

|||beskrivelse av kode og framgangsmåte på numeriske eksperimenter||


\section{Results} \label{results}

|||presentasjon og diskusjon av resultatene, samt sammenligning med \cite{SWL}|||


\section{Conclusion}

|||oppsummering og læringsutbytte|||


\end{multicols}
\bibliographystyle{unsrt}
\bibliography{FYS9411_project1}


\newpage
\appendix
\setcounter{equation}{0}
\renewcommand{\theequation}{\thesection\arabic{equation}}
\section*{APPENDIX}
\section{Calculations}

Some of the longer analytical calculations of the project are presented here.

\subsection{Local energy $\varepsilon$} \label{localenergy}
Equation \eqref{defLocalenergy} defines the local energy $\varepsilon$ through the Hamiltonian $H$ given in \eqref{Hamiltonian} and the trial wavefunction $\Psi$ given in \eqref{trialstate}. The potential terms $U$ og $V$ in the Hamiltonian give direct contributions to the local energy, but the kinetic term with its second derivative $\vec{\nabla}_i^2\Psi$ needs to be considered further. To this end, write
\begin{equation}
\Psi[\vec{R}] = G[\vec{R}]F[\vec{R}]
\end{equation}
with
\begin{align}
G[\vec{R}] &= \prod\limits_i^N g[\vec{r}_i] \\
F[\vec{R}] &= \prod\limits_j^N\prod\limits_{k > j}^N f[\Delta{r}_{jk}] 
\end{align}
and note that
\begin{equation}
\vec{\nabla}_i^2\Psi = \vec{\nabla}_i\cdot\left(\vec{\nabla}_i G F + G \vec{\nabla}_i F\right) = \vec{\nabla}_i^2 G F + 2\vec{\nabla}_i G \cdot \vec{\nabla}_i F + G \vec{\nabla}_i^2 F. \label{Lap_Psi_1} 
\end{equation}
Hence the derivatives of both $G$ and $F$ must be calculated in order to get an analytical expression for the local energy $\varepsilon$. The derivatives of $G$ are 
\begin{equation}
\vec{\nabla}_i G = \vec{\nabla}_i g[\vec{r}_i] \prod\limits_{j \neq i}^N g[\vec{r_j}] \quad\Longrightarrow\quad \vec{\nabla}_i^2 G = \vec{\nabla}_i^2 g[\vec{r}_i] \prod\limits_{j \neq i}^N g[\vec{r_j}],
\end{equation}
and because the derivatives of $g$ are
\begin{align}
\vec{\nabla}_i g[\vec{r}_i] &= -2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)g[\vec{r}_i] \\
\Longrightarrow \vec{\nabla}_i^2 g[\vec{r}_i] &= -2\alpha\left(\Big(D+(\beta-1)\Big)g[\vec{r}_i]+\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)\cdot\vec{\nabla}_i g[\vec{r}_i]\right) \nonumber\\
&= 2\alpha\left(2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)^2-\Big(D+(\beta-1)\Big)\right)g[\vec{r}_i]
\end{align}
these are quite simply given by
\begin{align}
&\vec{\nabla}_i G = -2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)G, \label{grad_G}\\
&\vec{\nabla}_i^2G = 2\alpha\left(2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)^2-\Big(D+(\beta-1)\Big)\right)G. \label{Lap_G}
\end{align}
To find the derivatives of $F$, rewrite the product to the exponential form 
\begin{equation}
F[\vec{R}] = \epsilon^{\sum\limits_{j}^N\sum\limits_{k > j}^N \ln f[\Delta{r}_{jk}]},
\end{equation}
and note that
\begin{align}
\vec{\nabla}_i F &= \sum\limits_{j \neq i}^N \left(\frac{\vec{\nabla}_i f[\Delta{r}_{ij}]}{f[\Delta{r}_{ij}]}\right) F \\
\Longrightarrow \vec{\nabla}_i^2 F &= \sum\limits_{j \neq i}^N \left(\vec{\nabla}_i\cdot\left[\frac{\vec{\nabla}_i f[\Delta{r}_{ij}]}{f[\Delta{r}_{ij}]}\right]\right) F + \sum\limits_{j \neq i}^N \left(\frac{\vec{\nabla}_i f[\Delta{r}_{ij}]}{f[\Delta{r}_{ij}]}\right)\cdot \vec{\nabla}_i F \nonumber\\
&= \sum\limits_{j \neq i}^N \left(\frac{\vec{\nabla}_i^2 f[\Delta{r}_{ij}]}{f[\Delta{r}_{ij}]} - \frac{\left(\vec{\nabla}_i f[\Delta{r}_{ij}]\right)^2}{f^2[\Delta{r}_{ij}]}\right) F + \sum\limits_{j \neq i}^N \sum\limits_{k \neq i}^N \left(\frac{\vec{\nabla}_i f[\Delta{r}_{ij}] \cdot\vec{\nabla}_i f[\Delta{r}_{ik}]}{f[\Delta{r}_{ij}]f[\Delta{r}_{ik}]}\right) F \nonumber\\
&= \sum\limits_{j \neq i}^N \left(\frac{\vec{\nabla}_i^2 f[\Delta{r}_{ij}]}{f[\Delta{r}_{ij}]} + \sum\limits_{{k \neq i}\atop{k \neq j}}^N \frac{\vec{\nabla}_i f[\Delta{r}_{ij}] \cdot\vec{\nabla}_i f[\Delta{r}_{ik}]}{f[\Delta{r}_{ij}]f[\Delta{r}_{ik}]}\right) F.
\end{align}
The derivatives of $f$ are
\begin{align}
\vec{\nabla}_i f[\Delta{r}_{ij}] &= \frac{a\Delta\vec{r}_{ij}}{\Delta{r}_{ij}^3} \\
\Longrightarrow \vec{\nabla}_i^2 f[\Delta{r}_{ij}] &= \frac{aD}{\Delta{r}_{ij}^3}-\frac{3a\Delta\vec{r}_{ij}^2}{\Delta{r}_{ij}^5} \nonumber\\
&= \frac{a(D-3)}{\Delta{r}_{ij}^3}
\end{align}
as long as all $\Delta{r}_{ij} > a$. Now since
\begin{equation}
\Delta{r}_{ij} f[\Delta{r}_{ij}] = \Delta{r}_{ij}-a
\end{equation}
it follows that
\begin{align}
\vec{\nabla}_i F &= \sum\limits_{j \neq i}^N \left(\frac{a\Delta\vec{r}_{ij}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a)}\right) F, \label{grad_F}\\
\vec{\nabla}_i^2 F &= \sum\limits_{j \neq i}^N \left(\frac{a(D-3)}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a)} + \sum\limits_{{k \neq i}\atop{k \neq j}}^N \frac{a^2 \Delta\vec{r}_{ij} \cdot \Delta\vec{r}_{ik}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a) \Delta{r}_{ik}^2(\Delta{r}_{ik}-a)}\right) F. \label{Lap_F}
\end{align}

Then in total equation \eqref{Lap_Psi_1} takes the form
\begin{align}
\vec{\nabla}_i^2\Psi &= 2\alpha\left(2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)^2-\Big(D+(\beta-1)\Big)\right) \Psi \nonumber\\
&- 4\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big) \cdot \sum\limits_{j \neq i}^N \left(\frac{a\Delta\vec{r}_{ij}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a)}\right) \Psi \nonumber\\
&+ \sum\limits_{j \neq i}^N \left(\frac{a(D-3)}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a)} + \sum\limits_{{k \neq i}\atop{k \neq j}}^N \frac{a^2 \Delta\vec{r}_{ij} \cdot \Delta\vec{r}_{ik}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a) \Delta{r}_{ik}^2(\Delta{r}_{ik}-a)}\right) \Psi \nonumber\\
\Longrightarrow \frac{\vec{\nabla}_i^2\Psi}{\Psi} &= 2\alpha\left(2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)^2-\Big(D+(\beta-1)\Big)\right) \nonumber\\
&+ \sum\limits_{j \neq i}^N \frac{a(D-3) - 4\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big) \cdot a\Delta\vec{r}_{ij}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a)} \nonumber\\
&+ \sum\limits_{j \neq i}^N \sum\limits_{{k \neq i}\atop{k \neq j}}^N \frac{a^2 \Delta\vec{r}_{ij} \cdot \Delta\vec{r}_{ik}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a) \Delta{r}_{ik}^2(\Delta{r}_{ik}-a)}
\end{align}
and by introducing the quantities
\begin{align}
\vec{q}[\vec{r}_i] &= -4\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big), \label{q}\\
d[\Delta{r}_{ij}] &= \Delta{r}_{ij}^2(\Delta{r}_{ij}-a), \label{d}\\
\vec{s}[\Delta\vec{r}_{ij}] &= \frac{a\Delta\vec{r}_{ij}}{2d[\Delta{r}_{ij}]}, \label{s}
\end{align}
it follows that the total analytic expression for the local energy is
\begin{align}
\varepsilon[\vec{R}] &= \alpha N\Big(D+(\beta-1)\Big) + \sum\limits_i^N \frac{1}{2}\left( U[\vec{r}_i] - \frac{1}{4}\vec{q}^2[\vec{r}_i] \right) \nonumber\\
&- \sum\limits_i^N \sum\limits_{j \neq i}^N \left( \frac{a(D-3)}{2d[\Delta{r}_{ij}]} + \vec{q}[\vec{r}_i] \cdot \vec{s}[\Delta\vec{r}_{ij}] \right) - 2\sum\limits_i^N \sum\limits_{j \neq i}^N \sum\limits_{{k \neq i}\atop{k \neq j}}^N \vec{s}[\Delta\vec{r}_{ij}] \cdot \vec{s}[\Delta\vec{r}_{ik}]
\end{align}
as long as all $\Delta r_{ij} > a$. This last restriction is why the hard-sphere interaction energy $V$ is omitted altogether; for configurations in which $\Delta r_{ij} \leq a$ for some $i$ and $j$, the trial wavefunction $\Psi$ in \eqref{trialstate} is defined to be zero (because $f[\Delta r_{ij}]$ is zero), which in turn means that the Metropolis algorithm will never sample such configurations, and so the fact that the local energy would be infinite for such configurations (because $V$ is infinite) is not a problem.

\subsection{Quantum drift $\vec{Q}$} \label{quantumdrift}
Equation \eqref{defQuantumdrift} defines the quantum drift of the system. From the calculations of section \ref{localenergy} it follows that
\begin{align}
\vec{\nabla}_i\Psi &= \vec{\nabla}_i G F + G \vec{\nabla}_i F \nonumber\\
&= -2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big)\Psi + \sum\limits_{j \neq i}^N \left(\frac{a\Delta\vec{r}_{ij}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a)}\right) \Psi \nonumber\\
\Longrightarrow \frac{\vec{\nabla}_i\Psi}{\Psi} &= -2\alpha\Big(\vec{r}_i+(\beta-1)\vec{z}_i\Big) + \sum\limits_{j \neq i}^N \left(\frac{a\Delta\vec{r}_{ij}}{\Delta{r}_{ij}^2(\Delta{r}_{ij}-a)}\right),
\end{align}
which means that the analytic expression for the quantum drift becomes
\begin{equation}
\vec{Q}_i[\vec{R}] = \vec{q}[\vec{r}_i] + 4\sum\limits_{j \neq i}^N \vec{s}[\Delta\vec{r}_{ij}].
\end{equation}
with the quantities introduced in \eqref{q}–\eqref{s}.


\newpage
\section{Code}

|||Julia-kode|||


\end{document}